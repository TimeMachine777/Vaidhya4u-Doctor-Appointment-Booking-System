# -*- coding: utf-8 -*-
"""NLP Project Sem 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ttuk5K-UxrKLJ0fSj2EbrxdptKKUjobk
"""

import pickle
import spacy
import numpy as np
import pandas as pd
from spellchecker import SpellChecker
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
nlp = spacy.load("en_core_web_sm")

f=open(r'D:\BIT MESRA\Semester 5\Subjects\NLP\Project\Final Project\Files\short_forms.pkl','rb')
short_forms=pickle.load(f)
f.close()

def socialmediacheck(word):
  if word in short_forms:
    return short_forms[word]
  else:
    return None

def spellchecker(word):
  word=word.lower()
  # spell = Speller() #autocorrect lib func
  spell = SpellChecker() #pyspellchecker lib func
  t1=socialmediacheck(word)
  if t1!=None:
    return t1
  else:
    return spell.correction(word)


#all the preprocessing of the text
#all the preprocessing of the text
def preprocess(text):
  doc=nlp(text)

  #getting all named entities (built in entites in SpaCy)
  ent_set=set({})
  for ent in doc.ents:
    if ent.label_ in ['PERSON','TIME']:
      ent_set.add(ent.text)
  # print("Ent set:")
  # for i in ent_set:
  #   print(i)

  #replacing all entities with a single word (for easy searching and storing those abbr in a dict for later so as to get back the original string)
  ent_all={}
  ct=-1 #key value for entities
  for i in ent_set:
    ent_all[str(ct)]=i
    text=text.replace(str(i),str(ct))
    ct-=1
  # print("Ent all:")
  # for i in ent_all:
  #   print(i,":",ent_all[i])
  # print("Text:",text)
  #creating final corrected and short form free text sentence

  doc=nlp(text)
  text_final=' '
  for tok in doc:
    if tok.text not in ent_all:
      text_final+=spellchecker(tok.text)
    else:
      text_final+=tok.text
    text_final+=" "

  for i in ent_all:
    text_final=text_final.replace(i,ent_all[i])
  # print("Final text is:",text_final)
  return text_final
#---------------------------------------------------------------

#preprocessing the dataset, performing word embedding and training the model
def modelTrain(): 
  #Getting text and label from dataset
  df=pd.read_csv(r'D:\BIT MESRA\Semester 5\Subjects\NLP\Project\Final Project\Files\Symptom2Disease.csv')
  labels = df['label'].tolist()
  text = df['text'].tolist()

  #pre-processing dataset text
  text_final = []
  for i in text:
    doc1 = nlp(i)
    sent= [tok.text.lower() for tok in doc1 if not tok.is_punct and not tok.is_space]
    sent_final= ' '.join(token for token in sent if token not in nlp.Defaults.stop_words)
    text_final.append(sent_final)

  #label substituting (pre-preprocessing dataset labels)
  label_to_no={}
  no_to_label={}
  ct=0
  for i in range(len(labels)):
    labels[i]=labels[i].lower()
    if labels[i] not in label_to_no:
      label_to_no[labels[i]]=ct
      no_to_label[ct]=labels[i]
      labels[i]=ct
      ct+=1
    else:
      labels[i]=label_to_no[labels[i]]

  labels=np.array([i for i in labels])

  #creating feature matrix for training data (using word vector of spacy)
  """ feature_matrix = []

  # Loop through the text data
  for i in text_final:
      # Process the text with spaCy
      doc1 = nlp(i)
      feature_matrix.append(doc1.vector)

  # Convert the list of feature matrices to a single numpy array
  feature_matrix = np.array(feature_matrix) """

  #creating feature matrix for training data (using tf-idf of sk-learn)
  vectorizer = TfidfVectorizer(max_features=5000)
  feature_matrix = vectorizer.fit_transform(text_final)

  #dividing data into train and test data
  text_train, text_test, labels_train, labels_test = train_test_split(feature_matrix, labels, test_size=0.2, random_state=41)

  #training model
  model=LogisticRegression()
  # model = MultinomialNB()
  # model = SVC(kernel='linear')
  # model = RandomForestClassifier(n_estimators=100, random_state=42)
  # model = MLPClassifier(hidden_layer_sizes=(100, ), max_iter=1000, random_state=42, activation='tanh')

  model.fit(text_train,labels_train)

  #Evaluation of model
  label_predict=model.predict(text_test)
  report_dict=classification_report(labels_test,label_predict)
  print(report_dict)
  return model,no_to_label,vectorizer,report_dict

#Now classification task begins
def classification(user_text,model,no_to_label,vectorizer):
  #sentence testing
  # nlp_l=spacy.load('en_core_web_lg')
  # user_text="Hello my name is Gaurang Dixit and I have loose motion and pain in the stomach"
  # user_text="Hi myself Vishwak, I am having cough,cold and high fever."
  user_text_final=preprocess(user_text)
  # print("Final text is:",user_text_final)
  doc=nlp(user_text_final)
  tokens= [tok.text.lower() for tok in doc if not tok.is_punct and not tok.is_space]
  tokens= [token for token in tokens if token not in nlp.Defaults.stop_words]
  doc=nlp(' '.join(i for i in tokens)) #final nlp object

  predicted_label=model.predict(vectorizer.transform([doc.text]))
  # print(no_to_label[predicted_label[0]])

  return doc,user_text_final,no_to_label[predicted_label[0]]

def convert_time(time_str):
    
    # Split the time string by ':' and space to separate hours and minutes
    parts = time_str.split(':')
    hours, minutes = int(parts[0]), int(parts[1].split()[0])

    if(hours>12):
      return "NV"
    if(minutes>59):
      return "NV"

    # Check if it's AM or PM and adjust the hours if necessary
    if "pm" in time_str.lower() and hours != 12:
        hours += 12
    elif "am" in time_str.lower() and hours == 12:
        hours = 0

    # Convert hours and minutes to a 4-digit string
    time_24hr = f"{hours:02}{minutes:02}"

    return time_24hr

def time_finder(user_text_final): #if any time is mentioned or else return general time
  doc=nlp(user_text_final)
  for i in doc.ents:
    if i.label_=='TIME':
      return convert_time(i.text)
  return None

if __name__== '__main__':
  # myself Gaurang and I need to book an appointment at 5:30 pm because of sore throat, cough, and high fever.
  model,no_to_label,vectorizer,report_dict=modelTrain()

  while(True):
    user_text=input("Enter user text:")
    doc,user_text_final,predicted_label=classification(user_text,model,no_to_label,vectorizer)

    print("user text final:",user_text_final)
    print("processed text(used for predicting):",doc.text)
    print("predicted label:",predicted_label)
    print("Time(hours): ",time_finder(user_text_final))
    print("--------------------------------")